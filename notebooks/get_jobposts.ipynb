{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35484b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from lxml import html\n",
    "import regex\n",
    "\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import pandas\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce668b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\n",
    "                    prog='get_linkedin_jobposts',\n",
    "                    description='Scrapes LinkedIn job posts for a given city'\n",
    "                    )\n",
    "\n",
    "parser.add_argument('-l', '--location', default='vancouver')\n",
    "\n",
    "# set default date to today\n",
    "today = datetime.now().strftime('%Y%m%d')\n",
    "parser.add_argument('-d', '--date', default=today)\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "# global arguments\n",
    "location = args.location\n",
    "date = args.date\n",
    "\n",
    "# destination file\n",
    "loc = ''.join(c for c in location if c.isalpha())\n",
    "dst = os.path.abspath(f'../data/jobposts/{date}-{loc}.csv')\n",
    "print('dst:', dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ee5b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_jobs(params):\n",
    "    \"\"\"\n",
    "    Generator function to scrape job posts from LinkedIn.\n",
    "    Note: Linkedin limits outputs to 1000 results per search parameter.\n",
    "    \"\"\"\n",
    "    \n",
    "    # URL for LinkedIn job posts\n",
    "    # Note: This URL may change, and scraping LinkedIn may violate their terms of service.\n",
    "    # Use responsibly and consider using their official API if available.\n",
    "    url = 'https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search'\n",
    "    headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36'\n",
    "        }\n",
    "    \n",
    "    # request the job postings\n",
    "    sleep = 1\n",
    "    while True:\n",
    "        resp = requests.get(url, params=params, headers=headers)\n",
    "        if resp.status_code == 429: # too many requests\n",
    "            time.sleep(sleep)\n",
    "            sleep += 1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "\n",
    "    print('resp-url:', resp.url)\n",
    "\n",
    "    # exit function if bad response or empty HTML document\n",
    "    if (not resp) or ('<!DOCTYPE html>\\n\\n<!---->' in resp.text):\n",
    "        print('-'*50)\n",
    "        print(f'request-url [status {resp.status_code}]: {resp.url}')\n",
    "        print('Bad request or no more jobs found.') # TODO: \n",
    "        yield\n",
    "\n",
    "    # iterate over job list items\n",
    "    doc = html.fromstring(resp.content)\n",
    "    lis = doc.xpath('//li')\n",
    "    \n",
    "    for li in lis:\n",
    "\n",
    "        # get the text content of the job posting\n",
    "        texts = li.xpath('.//text()')\n",
    "        texts = [regex.sub(r'\\s+', ' ', x).strip() for x in texts]\n",
    "        \n",
    "        # remove empty strings\n",
    "        texts = [x for x in texts if x] \n",
    "\n",
    "        # remove duplicate text\n",
    "        texts = list(dict.fromkeys(texts))\n",
    "\n",
    "        # get links of job postings\n",
    "        anchors = li.xpath('.//a')\n",
    "        hrefs = [a.get('href') for a in anchors]\n",
    "\n",
    "        # yield result\n",
    "        res = {\n",
    "            'position' : texts[0]   if len(texts) > 0 else None,\n",
    "            'company' : texts[1]    if len(texts) > 1 else None,\n",
    "            'location' : texts[2]   if len(texts) > 2 else None,\n",
    "            'status' : texts[3]     if len(texts) > 3 else None,\n",
    "            'job_url' : hrefs[0].split('?')[0],\n",
    "            'firm_url': hrefs[1]    if len(hrefs) > 1 else None,\n",
    "            'search_keyword' : params['keywords'],\n",
    "        }\n",
    "\n",
    "        yield res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c4adca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_jobs(location):\n",
    "    '''\n",
    "    Get number of jobs from search page\n",
    "    '''\n",
    "    \n",
    "    # approx. number of job postings\n",
    "    url = f'https://www.linkedin.com/jobs/search?location={location}'\n",
    "    resp = requests.get(url)\n",
    "    doc = html.fromstring(resp.content)\n",
    "    njobs = doc.xpath('//span[@class=\"results-context-header__job-count\"]//text()')[0]\n",
    "\n",
    "    return int(''.join(c for c in njobs if c.isnumeric()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5d6de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data, dst=dst):\n",
    "    '''\n",
    "    Save data\n",
    "    '''\n",
    "\n",
    "    df = pandas.DataFrame(data)\n",
    "    \n",
    "    df.to_csv(dst, index=False)\n",
    "\n",
    "    print(f'Saved {df.shape}:', dst)\n",
    "    print('Now:', datetime.now().strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5db6f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freq(data):\n",
    "    '''\n",
    "    Get keyword frequency from job post and companies\n",
    "    \n",
    "    TODO: create filter for searched keywords\n",
    "    '''\n",
    "    \n",
    "    df = pandas.DataFrame(data)\n",
    "\n",
    "    # get keywords from job postings\n",
    "    pos_str = ' '.join(df['position'].tolist())\n",
    "    comp_str = ' '.join(df['company'].tolist())\n",
    "    join_str = pos_str + ' ' + comp_str\n",
    "    join_str = join_str.lower()\n",
    "\n",
    "    # remove non-alphabetic characters\n",
    "    remove = [c for c in set(join_str) if not c.isalpha()]\n",
    "    for c in remove:\n",
    "        join_str = join_str.replace(c, ' ')\n",
    "\n",
    "    words = join_str.split()\n",
    "\n",
    "    # get word frequencies\n",
    "    res = [{'keyword' : w, 'count' : words.count(w)} for w in set(words) if len(w) > 2]\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2132ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    print('Location:', location)\n",
    "    print('Start time:', datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "    njobs = get_number_jobs(location)\n",
    "\n",
    "    if not os.path.exists(dst):\n",
    "        \n",
    "        # initialize empty data structures\n",
    "        data = []\n",
    "        job_urls = set()\n",
    "        searched_kws = set()\n",
    "        kw = ''\n",
    "\n",
    "    else:\n",
    "        \n",
    "        # initialized from saved data\n",
    "        df = pandas.read_csv(dst)\n",
    "        \n",
    "        data = df.to_dict(orient='records')\n",
    "        job_urls = set(df['job_url'])\n",
    "        searched_kws = set(df['search_keyword'].dropna())\n",
    "        kw = df['search_keyword'].dropna().iloc[-1]\n",
    "\n",
    "        print(f'Continue from previous {len(data):,} records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cca859",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # break outer loop if most jobs found or no new keywords found\n",
    "    while True:\n",
    "\n",
    "        print('*'*50)\n",
    "        print(f'search-keyword ({len(searched_kws):,}):', kw)\n",
    "\n",
    "        # break inner loop if no more results in page (usually 10 results)\n",
    "        run_search, start = True, 0\n",
    "        while run_search:\n",
    "\n",
    "            params = {\n",
    "                'location': location,\n",
    "                'start': start,\n",
    "                'keywords' : kw,\n",
    "                }\n",
    "            \n",
    "            search_results = search_jobs(params)\n",
    "            for search_res in search_results:\n",
    "\n",
    "                start += 1 # local counter (inner loop)\n",
    "\n",
    "                # break inner loop if no more results\n",
    "                if not search_res:\n",
    "                    run_search = False\n",
    "                    break\n",
    "\n",
    "                # add to data if new job url\n",
    "                job_url = search_res['job_url'].split('?')[0]\n",
    "                \n",
    "                if job_url not in job_urls:\n",
    "                    job_urls.add(job_url)\n",
    "                    data.append(search_res)\n",
    "\n",
    "                    # report progress\n",
    "                    print(f'[job {len(data):,} of {njobs:,}+]', datetime.now(), job_url)\n",
    "\n",
    "        # save data\n",
    "        save_data(data)\n",
    "\n",
    "        # break outer loop if most jobs found\n",
    "        if len(data) >= njobs:\n",
    "            print('Most jobs found.')\n",
    "            break\n",
    "\n",
    "        # get word frequencies\n",
    "        freq = get_freq(data)\n",
    "\n",
    "        # filter top unsearched keyword\n",
    "        wf = pandas.DataFrame(freq)\n",
    "        wf = wf.sort_values(by='count', ascending=False)\n",
    "        cond = ~wf['keyword'].isin(searched_kws)\n",
    "        kws = wf[cond]\n",
    "\n",
    "        # break outer loop if no new keywords found\n",
    "        if kws.empty:\n",
    "            print('No more keywords found.')\n",
    "            break\n",
    "\n",
    "        # add new keyword to list of searched\n",
    "        kw = kws.iloc[0]['keyword']\n",
    "        searched_kws.add(kw)\n",
    "\n",
    "\n",
    "    print('=' * 50)\n",
    "    print('Script complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e196440a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
